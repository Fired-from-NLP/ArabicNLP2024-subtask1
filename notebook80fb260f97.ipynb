{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8322662,"sourceType":"datasetVersion","datasetId":4929193}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-07T19:20:31.018509Z","iopub.execute_input":"2024-05-07T19:20:31.018950Z","iopub.status.idle":"2024-05-07T19:20:31.036164Z","shell.execute_reply.started":"2024-05-07T19:20:31.018916Z","shell.execute_reply":"2024-05-07T19:20:31.035375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install openpyxl\n!pip install gdown\n!pip install farasapy","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:20:31.040669Z","iopub.execute_input":"2024-05-07T19:20:31.041390Z","iopub.status.idle":"2024-05-07T19:21:07.262476Z","shell.execute_reply.started":"2024-05-07T19:20:31.041335Z","shell.execute_reply":"2024-05-07T19:21:07.261409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown 1h620Wmx1yvkTKibH6N2wCNddOakBTUzg -O data.xlsx\n!git clone https://github.com/aub-mind/arabert","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:00.881897Z","iopub.execute_input":"2024-05-07T19:22:00.882801Z","iopub.status.idle":"2024-05-07T19:22:05.114692Z","shell.execute_reply.started":"2024-05-07T19:22:00.882760Z","shell.execute_reply":"2024-05-07T19:22:05.113555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TFBertModel, BertTokenizer, BertConfig\nimport tensorflow as tf\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nfrom arabert.preprocess import ArabertPreprocessor\n\narabert_prep = ArabertPreprocessor(model_name='aubmindlab/bert-base-arabertv02-twitter',keep_emojis=False)\nMAX_LENGHT = 128\nconfig = BertConfig.from_pretrained( 'aubmindlab/bert-base-arabertv02-twitter', output_hidden_states=False)    \npre = BertTokenizer.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\")\nbert = TFBertModel.from_pretrained(\"aubmindlab/bert-base-arabertv02-twitter\", config=config, from_pt=True, trainable=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:07.596658Z","iopub.execute_input":"2024-05-07T19:22:07.597177Z","iopub.status.idle":"2024-05-07T19:22:09.953316Z","shell.execute_reply.started":"2024-05-07T19:22:07.597130Z","shell.execute_reply":"2024-05-07T19:22:09.952391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/MSA-Train.csv')\n\nmf.rename(columns = {'Query_MSA' : 'Query'}, inplace = True)\nmf.rename(columns = {'Query_ID_MSA' : 'Query_ID'}, inplace = True)\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:12.192034Z","iopub.execute_input":"2024-05-07T19:22:12.192434Z","iopub.status.idle":"2024-05-07T19:22:12.257318Z","shell.execute_reply.started":"2024-05-07T19:22:12.192401Z","shell.execute_reply":"2024-05-07T19:22:12.256422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/PAL-Train.csv')\n\npf.rename(columns = {'Query_PAL' : 'Query'}, inplace = True)\npf.rename(columns = {'Query_ID_PAL' : 'Query_ID'}, inplace = True)\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:13.368159Z","iopub.execute_input":"2024-05-07T19:22:13.368790Z","iopub.status.idle":"2024-05-07T19:22:13.422844Z","shell.execute_reply.started":"2024-05-07T19:22:13.368752Z","shell.execute_reply":"2024-05-07T19:22:13.421933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf['dialect'] = 'MSA'\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:14.478961Z","iopub.execute_input":"2024-05-07T19:22:14.479732Z","iopub.status.idle":"2024-05-07T19:22:14.492499Z","shell.execute_reply.started":"2024-05-07T19:22:14.479701Z","shell.execute_reply":"2024-05-07T19:22:14.491516Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf['dialect'] = 'PAL'\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:15.376234Z","iopub.execute_input":"2024-05-07T19:22:15.376934Z","iopub.status.idle":"2024-05-07T19:22:15.390331Z","shell.execute_reply.started":"2024-05-07T19:22:15.376904Z","shell.execute_reply":"2024-05-07T19:22:15.389407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([mf, pf], ignore_index = True)\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:16.346034Z","iopub.execute_input":"2024-05-07T19:22:16.346748Z","iopub.status.idle":"2024-05-07T19:22:16.361272Z","shell.execute_reply.started":"2024-05-07T19:22:16.346714Z","shell.execute_reply":"2024-05-07T19:22:16.360375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:19.231063Z","iopub.execute_input":"2024-05-07T19:22:19.231926Z","iopub.status.idle":"2024-05-07T19:22:19.237655Z","shell.execute_reply.started":"2024-05-07T19:22:19.231893Z","shell.execute_reply":"2024-05-07T19:22:19.236722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = df['Intent_en'].unique().tolist()\nprint(classes)\nlen(classes)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:24.773182Z","iopub.execute_input":"2024-05-07T19:22:24.773960Z","iopub.status.idle":"2024-05-07T19:22:24.782693Z","shell.execute_reply.started":"2024-05-07T19:22:24.773927Z","shell.execute_reply":"2024-05-07T19:22:24.781693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dialects = df['dialect'].unique().tolist()\nprint(dialects)\nlen(dialects)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:26.304967Z","iopub.execute_input":"2024-05-07T19:22:26.305592Z","iopub.status.idle":"2024-05-07T19:22:26.314080Z","shell.execute_reply.started":"2024-05-07T19:22:26.305558Z","shell.execute_reply":"2024-05-07T19:22:26.313066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df\n\ndf1.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:28.346982Z","iopub.execute_input":"2024-05-07T19:22:28.347643Z","iopub.status.idle":"2024-05-07T19:22:28.365771Z","shell.execute_reply.started":"2024-05-07T19:22:28.347614Z","shell.execute_reply":"2024-05-07T19:22:28.364407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/MSA-Dev.csv')\n\nmf.rename(columns = {'Query_MSA' : 'Query'}, inplace = True)\nmf.rename(columns = {'Query_ID_MSA' : 'Query_ID'}, inplace = True)\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:29.376870Z","iopub.execute_input":"2024-05-07T19:22:29.377404Z","iopub.status.idle":"2024-05-07T19:22:29.398629Z","shell.execute_reply.started":"2024-05-07T19:22:29.377376Z","shell.execute_reply":"2024-05-07T19:22:29.397761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf['dialect'] = 'MSA'\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:31.580989Z","iopub.execute_input":"2024-05-07T19:22:31.582050Z","iopub.status.idle":"2024-05-07T19:22:31.593679Z","shell.execute_reply.started":"2024-05-07T19:22:31.582015Z","shell.execute_reply":"2024-05-07T19:22:31.592814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/PAL-Dev.csv')\n\npf.rename(columns = {'Query_PAL' : 'Query'}, inplace = True)\npf.rename(columns = {'Query_ID_PAL' : 'Query_ID'}, inplace = True)\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:33.202153Z","iopub.execute_input":"2024-05-07T19:22:33.202886Z","iopub.status.idle":"2024-05-07T19:22:33.223456Z","shell.execute_reply.started":"2024-05-07T19:22:33.202853Z","shell.execute_reply":"2024-05-07T19:22:33.222527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf['dialect'] = 'PAL'\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:34.832180Z","iopub.execute_input":"2024-05-07T19:22:34.832834Z","iopub.status.idle":"2024-05-07T19:22:34.844791Z","shell.execute_reply.started":"2024-05-07T19:22:34.832802Z","shell.execute_reply":"2024-05-07T19:22:34.843886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.concat([df1, mf], ignore_index = True)\n\ndf1 = pd.concat([df1, pf], ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:36.211124Z","iopub.execute_input":"2024-05-07T19:22:36.211810Z","iopub.status.idle":"2024-05-07T19:22:36.221704Z","shell.execute_reply.started":"2024-05-07T19:22:36.211776Z","shell.execute_reply":"2024-05-07T19:22:36.220720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:37.845118Z","iopub.execute_input":"2024-05-07T19:22:37.845561Z","iopub.status.idle":"2024-05-07T19:22:37.851763Z","shell.execute_reply.started":"2024-05-07T19:22:37.845530Z","shell.execute_reply":"2024-05-07T19:22:37.850795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['dialect'].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:39.658498Z","iopub.execute_input":"2024-05-07T19:22:39.658849Z","iopub.status.idle":"2024-05-07T19:22:39.667067Z","shell.execute_reply.started":"2024-05-07T19:22:39.658823Z","shell.execute_reply":"2024-05-07T19:22:39.666092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf = pd.read_csv('/kaggle/input/arabic-nlp/data/Banking77_Arabized_MSA_test_sample.csv')\n\nmf.rename(columns = {'text' : 'Query'}, inplace = True)\n\nmf = mf.drop(['label'], axis = 1)\n\nmf['dialect'] = 'MSA'\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:41.126975Z","iopub.execute_input":"2024-05-07T19:22:41.127298Z","iopub.status.idle":"2024-05-07T19:22:41.142759Z","shell.execute_reply.started":"2024-05-07T19:22:41.127271Z","shell.execute_reply":"2024-05-07T19:22:41.141904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf = pd.read_csv('/kaggle/input/arabic-nlp/data/Banking77_Arabized_PAL_test_sample.csv')\n\npf.rename(columns = {'text' : 'Query'}, inplace = True)\n\npf = pf.drop(['label'], axis = 1)\n\npf['dialect'] = 'PAL'\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:42.620333Z","iopub.execute_input":"2024-05-07T19:22:42.620732Z","iopub.status.idle":"2024-05-07T19:22:42.635325Z","shell.execute_reply.started":"2024-05-07T19:22:42.620701Z","shell.execute_reply":"2024-05-07T19:22:42.634313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = pd.concat([df1, mf], ignore_index = True)\n\ndf1 = pd.concat([df1, pf], ignore_index = True)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:44.137935Z","iopub.execute_input":"2024-05-07T19:22:44.138271Z","iopub.status.idle":"2024-05-07T19:22:44.150096Z","shell.execute_reply.started":"2024-05-07T19:22:44.138245Z","shell.execute_reply":"2024-05-07T19:22:44.149156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:45.902680Z","iopub.execute_input":"2024-05-07T19:22:45.903282Z","iopub.status.idle":"2024-05-07T19:22:45.909301Z","shell.execute_reply.started":"2024-05-07T19:22:45.903239Z","shell.execute_reply":"2024-05-07T19:22:45.908289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1['Query'] = df1['Query'].apply(lambda x: arabert_prep.preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:50.293942Z","iopub.execute_input":"2024-05-07T19:22:50.294667Z","iopub.status.idle":"2024-05-07T19:22:53.430033Z","shell.execute_reply.started":"2024-05-07T19:22:50.294632Z","shell.execute_reply":"2024-05-07T19:22:53.429226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_valid, y_train, y_valid = train_test_split(df1[\"Query\"], df1[\"dialect\"],\n                                                    stratify=df1[\"dialect\"], \n                                                    test_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:55.353903Z","iopub.execute_input":"2024-05-07T19:22:55.354661Z","iopub.status.idle":"2024-05-07T19:22:55.394685Z","shell.execute_reply.started":"2024-05-07T19:22:55.354629Z","shell.execute_reply":"2024-05-07T19:22:55.393700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X = X.apply(lambda x: pre(x, return_tensors=\"tf\"))\ny_train = y_train.apply(lambda x: dialects.index(x))\ny_valid = y_valid.apply(lambda x: dialects.index(x))\n\nX_train = pre(X_train.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\nX_valid = pre(X_valid.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\n#print(pre_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:22:59.367179Z","iopub.execute_input":"2024-05-07T19:22:59.368137Z","iopub.status.idle":"2024-05-07T19:23:07.902073Z","shell.execute_reply.started":"2024-05-07T19:22:59.368102Z","shell.execute_reply":"2024-05-07T19:23:07.901276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninput_text = tf.keras.Input(shape=(MAX_LENGHT,), dtype=tf.int32, name=\"input\")\n#preprocessing = keras.layers.Lambda(lambda_layer, name=\"lambda_layer\")(text.tolist())\nbert_output = bert(input_text)\n\nnet = tf.keras.layers.Dropout(0.5, name='DropOut1')(bert_output['pooler_output'])\nnet = tf.keras.layers.Dense(units=768, activation='tanh', name='classifier')(net)\nnet = tf.keras.layers.Dropout(0.5, name='DropOut2')(net)\nnet = tf.keras.layers.Dense(units=len(dialects), activation='softmax', name='output')(net)\n\nmodel = tf.keras.Model(input_text, net)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:23:14.708129Z","iopub.execute_input":"2024-05-07T19:23:14.708542Z","iopub.status.idle":"2024-05-07T19:23:22.377706Z","shell.execute_reply.started":"2024-05-07T19:23:14.708509Z","shell.execute_reply":"2024-05-07T19:23:22.376924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.SparseCategoricalCrossentropy()\nmetrics = tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n              loss=loss,\n              metrics=metrics\n            )","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:23:24.285134Z","iopub.execute_input":"2024-05-07T19:23:24.285915Z","iopub.status.idle":"2024-05-07T19:23:24.308494Z","shell.execute_reply.started":"2024-05-07T19:23:24.285883Z","shell.execute_reply":"2024-05-07T19:23:24.307749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n                    x = X_train['input_ids'],\n                    y = y_train,\n                    validation_data = (X_valid['input_ids'], y_valid),\n                    epochs=20,\n                   shuffle=True\n                   )","metadata":{"execution":{"iopub.status.busy":"2024-05-07T19:23:26.979819Z","iopub.execute_input":"2024-05-07T19:23:26.980640Z","iopub.status.idle":"2024-05-07T21:07:53.352894Z","shell.execute_reply.started":"2024-05-07T19:23:26.980605Z","shell.execute_reply":"2024-05-07T21:07:53.352015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history.history.keys())\nloss_train = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(len(loss_train))\n\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('fig-loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:00.283824Z","iopub.execute_input":"2024-05-07T21:08:00.284516Z","iopub.status.idle":"2024-05-07T21:08:00.670211Z","shell.execute_reply.started":"2024-05-07T21:08:00.284482Z","shell.execute_reply":"2024-05-07T21:08:00.669388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history.history.keys())\nacc_train = history.history['acc']\nacc_val = history.history['val_acc']\nepochs = range(len(acc_train))\n\nplt.plot(epochs, acc_train, 'g', label='Training Accuracy')\nplt.plot(epochs, acc_val, 'b', label='validation Accuracy')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('fig-Accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:15.484140Z","iopub.execute_input":"2024-05-07T21:08:15.484551Z","iopub.status.idle":"2024-05-07T21:08:15.825582Z","shell.execute_reply.started":"2024-05-07T21:08:15.484517Z","shell.execute_reply":"2024-05-07T21:08:15.824643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:21.386359Z","iopub.execute_input":"2024-05-07T21:08:21.387496Z","iopub.status.idle":"2024-05-07T21:08:21.397522Z","shell.execute_reply.started":"2024-05-07T21:08:21.387452Z","shell.execute_reply":"2024-05-07T21:08:21.396549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(classes)\nexample = \"عندكم معلومات عن بطاقة الدفع عند الاستلام؟\"\nids = pre(example, return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)['input_ids']\npred = model.predict(ids)\nindex = tf.math.argmax(pred[0])\nprint(dialects[index] + \" with percentage: \" + str(pred[0][index] * 100) + \"\\n\")\n\nscores = {}\nfor i in range(len(dialects)):\n    scores[dialects[i]] = pred[0][i] * 100\n\nscores = {k: v for k, v in sorted(scores.items(), key=lambda item: item[1], reverse=True)}\nfor k,v in scores.items():\n    print(k + \" with percentage: \" + \"{:.2f}\".format(v))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:23.336525Z","iopub.execute_input":"2024-05-07T21:08:23.337175Z","iopub.status.idle":"2024-05-07T21:08:34.096678Z","shell.execute_reply.started":"2024-05-07T21:08:23.337143Z","shell.execute_reply":"2024-05-07T21:08:34.095721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(dialects[index])","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:39.296525Z","iopub.execute_input":"2024-05-07T21:08:39.297326Z","iopub.status.idle":"2024-05-07T21:08:39.302609Z","shell.execute_reply.started":"2024-05-07T21:08:39.297280Z","shell.execute_reply":"2024-05-07T21:08:39.301629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/MSA-Train.csv')\n\nmf.rename(columns = {'Query_MSA' : 'Query'}, inplace = True)\nmf.rename(columns = {'Query_ID_MSA' : 'Query_ID'}, inplace = True)\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:42.788443Z","iopub.execute_input":"2024-05-07T21:08:42.788834Z","iopub.status.idle":"2024-05-07T21:08:42.853650Z","shell.execute_reply.started":"2024-05-07T21:08:42.788802Z","shell.execute_reply":"2024-05-07T21:08:42.852715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/PAL-Train.csv')\n\npf.rename(columns = {'Query_PAL' : 'Query'}, inplace = True)\npf.rename(columns = {'Query_ID_PAL' : 'Query_ID'}, inplace = True)\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:44.746458Z","iopub.execute_input":"2024-05-07T21:08:44.746848Z","iopub.status.idle":"2024-05-07T21:08:44.805253Z","shell.execute_reply.started":"2024-05-07T21:08:44.746817Z","shell.execute_reply":"2024-05-07T21:08:44.804266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf['Query'] = mf['Query'].apply(lambda x: arabert_prep.preprocess(x))\npf['Query'] = pf['Query'].apply(lambda x: arabert_prep.preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:46.740003Z","iopub.execute_input":"2024-05-07T21:08:46.740716Z","iopub.status.idle":"2024-05-07T21:08:49.527353Z","shell.execute_reply.started":"2024-05-07T21:08:46.740682Z","shell.execute_reply":"2024-05-07T21:08:49.526349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train1, X_valid1, y_train1, y_valid1 = train_test_split(mf[\"Query\"], mf[\"Intent_en\"],\n                                                    stratify=mf[\"Intent_en\"], \n                                                    test_size=0.1)\n\n\nX_train2, X_valid2, y_train2, y_valid2 = train_test_split(pf[\"Query\"], pf[\"Intent_en\"],\n                                                    stratify=pf[\"Intent_en\"], \n                                                    test_size=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:51.387255Z","iopub.execute_input":"2024-05-07T21:08:51.387647Z","iopub.status.idle":"2024-05-07T21:08:51.429335Z","shell.execute_reply.started":"2024-05-07T21:08:51.387616Z","shell.execute_reply":"2024-05-07T21:08:51.428553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/MSA-Dev.csv')\n\nmf.rename(columns = {'Query_MSA' : 'Query'}, inplace = True)\nmf.rename(columns = {'Query_ID_MSA' : 'Query_ID'}, inplace = True)\n\nmf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:53.286379Z","iopub.execute_input":"2024-05-07T21:08:53.287254Z","iopub.status.idle":"2024-05-07T21:08:53.312314Z","shell.execute_reply.started":"2024-05-07T21:08:53.287224Z","shell.execute_reply":"2024-05-07T21:08:53.311493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/PAL-Dev.csv')\n\npf.rename(columns = {'Query_PAL' : 'Query'}, inplace = True)\npf.rename(columns = {'Query_ID_PAL' : 'Query_ID'}, inplace = True)\n\npf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:55.353071Z","iopub.execute_input":"2024-05-07T21:08:55.353556Z","iopub.status.idle":"2024-05-07T21:08:55.375530Z","shell.execute_reply.started":"2024-05-07T21:08:55.353524Z","shell.execute_reply":"2024-05-07T21:08:55.374612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mf['Query'] = mf['Query'].apply(lambda x: arabert_prep.preprocess(x))\npf['Query'] = pf['Query'].apply(lambda x: arabert_prep.preprocess(x))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:08:58.535669Z","iopub.execute_input":"2024-05-07T21:08:58.536351Z","iopub.status.idle":"2024-05-07T21:08:58.862169Z","shell.execute_reply.started":"2024-05-07T21:08:58.536311Z","shell.execute_reply":"2024-05-07T21:08:58.861246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid1 = pd.concat([X_valid1, mf['Query']], ignore_index=True)\nprint(X_valid1.shape)\n\nX_valid2 = pd.concat([X_valid2, pf['Query']], ignore_index=True)\nprint(X_valid2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:09:01.221065Z","iopub.execute_input":"2024-05-07T21:09:01.221873Z","iopub.status.idle":"2024-05-07T21:09:01.228634Z","shell.execute_reply.started":"2024-05-07T21:09:01.221838Z","shell.execute_reply":"2024-05-07T21:09:01.227698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_valid1 = pd.concat([y_valid1, mf['Intent_en']], ignore_index=True)\nprint(y_valid1.shape)\n\ny_valid2 = pd.concat([y_valid2, pf['Intent_en']], ignore_index=True)\nprint(y_valid2.shape)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:09:02.685955Z","iopub.execute_input":"2024-05-07T21:09:02.686823Z","iopub.status.idle":"2024-05-07T21:09:02.693028Z","shell.execute_reply.started":"2024-05-07T21:09:02.686791Z","shell.execute_reply":"2024-05-07T21:09:02.692099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#X = X.apply(lambda x: pre(x, return_tensors=\"tf\"))\ny_train1 = y_train1.apply(lambda x: classes.index(x))\ny_valid1 = y_valid1.apply(lambda x: classes.index(x))\n\nX_train1 = pre(X_train1.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\nX_valid1 = pre(X_valid1.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\n#print(pre_data)\n\n#X = X.apply(lambda x: pre(x, return_tensors=\"tf\"))\ny_train2 = y_train2.apply(lambda x: classes.index(x))\ny_valid2 = y_valid2.apply(lambda x: classes.index(x))\n\nX_train2 = pre(X_train2.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\nX_valid2 = pre(X_valid2.tolist(), return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)\n#print(pre_data)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:09:05.199654Z","iopub.execute_input":"2024-05-07T21:09:05.200548Z","iopub.status.idle":"2024-05-07T21:09:21.429421Z","shell.execute_reply.started":"2024-05-07T21:09:05.200513Z","shell.execute_reply":"2024-05-07T21:09:21.428587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninput_text = tf.keras.Input(shape=(MAX_LENGHT,), dtype=tf.int32, name=\"input\")\n#preprocessing = keras.layers.Lambda(lambda_layer, name=\"lambda_layer\")(text.tolist())\nbert_output = bert(input_text)\n\nnet = tf.keras.layers.Dropout(0.5, name='DropOut1')(bert_output['pooler_output'])\nnet = tf.keras.layers.Dense(units=768, activation='tanh', name='classifier')(net)\nnet = tf.keras.layers.Dropout(0.5, name='DropOut2')(net)\nnet = tf.keras.layers.Dense(units=len(classes), activation='softmax', name='output')(net)\n\nmodel1 = tf.keras.Model(input_text, net)\nmodel2 = tf.keras.Model(input_text, net)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:09:27.218871Z","iopub.execute_input":"2024-05-07T21:09:27.219252Z","iopub.status.idle":"2024-05-07T21:09:35.641450Z","shell.execute_reply.started":"2024-05-07T21:09:27.219223Z","shell.execute_reply":"2024-05-07T21:09:35.640484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss = tf.keras.losses.SparseCategoricalCrossentropy()\nmetrics = tf.keras.metrics.SparseCategoricalAccuracy(name=\"acc\")\n\nmodel1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n              loss=loss,\n              metrics=metrics\n            )\n\nmodel2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-6),\n              loss=loss,\n              metrics=metrics\n            )","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:09:37.406978Z","iopub.execute_input":"2024-05-07T21:09:37.407332Z","iopub.status.idle":"2024-05-07T21:09:37.441512Z","shell.execute_reply.started":"2024-05-07T21:09:37.407302Z","shell.execute_reply":"2024-05-07T21:09:37.440571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history1 = model1.fit(\n                    x = X_train1['input_ids'],\n                    y = y_train1,\n                    validation_data = (X_valid1['input_ids'], y_valid1),\n                    epochs=30,\n                   shuffle=True\n                   )","metadata":{"execution":{"iopub.status.busy":"2024-05-07T21:09:45.672398Z","iopub.execute_input":"2024-05-07T21:09:45.673120Z","iopub.status.idle":"2024-05-07T22:26:44.894168Z","shell.execute_reply.started":"2024-05-07T21:09:45.673088Z","shell.execute_reply":"2024-05-07T22:26:44.893318Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history1.history.keys())\nloss_train = history1.history['loss']\nloss_val = history1.history['val_loss']\nepochs = range(len(loss_train))\n\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('fig-loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T22:26:53.301593Z","iopub.execute_input":"2024-05-07T22:26:53.302090Z","iopub.status.idle":"2024-05-07T22:26:53.609584Z","shell.execute_reply.started":"2024-05-07T22:26:53.302052Z","shell.execute_reply":"2024-05-07T22:26:53.608699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history1.history.keys())\nacc_train = history1.history['acc']\nacc_val = history1.history['val_acc']\nepochs = range(len(acc_train))\n\nplt.plot(epochs, acc_train, 'g', label='Training Accuracy')\nplt.plot(epochs, acc_val, 'b', label='validation Accuracy')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('fig-Accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T22:27:03.317986Z","iopub.execute_input":"2024-05-07T22:27:03.319062Z","iopub.status.idle":"2024-05-07T22:27:03.645917Z","shell.execute_reply.started":"2024-05-07T22:27:03.319027Z","shell.execute_reply":"2024-05-07T22:27:03.644972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history2 = model2.fit(\n                    x = X_train2['input_ids'],\n                    y = y_train2,\n                    validation_data = (X_valid2['input_ids'], y_valid2),\n                    epochs=30,\n                   shuffle=True\n                   )","metadata":{"execution":{"iopub.status.busy":"2024-05-07T22:27:14.150668Z","iopub.execute_input":"2024-05-07T22:27:14.151524Z","iopub.status.idle":"2024-05-07T23:45:37.923411Z","shell.execute_reply.started":"2024-05-07T22:27:14.151491Z","shell.execute_reply":"2024-05-07T23:45:37.922401Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history2.history.keys())\nloss_train = history2.history['loss']\nloss_val = history2.history['val_loss']\nepochs = range(len(loss_train))\n\nplt.plot(epochs, loss_train, 'g', label='Training loss')\nplt.plot(epochs, loss_val, 'b', label='validation loss')\nplt.title('Training loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.savefig('fig-loss.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T23:45:48.063199Z","iopub.execute_input":"2024-05-07T23:45:48.063689Z","iopub.status.idle":"2024-05-07T23:45:48.402993Z","shell.execute_reply.started":"2024-05-07T23:45:48.063645Z","shell.execute_reply":"2024-05-07T23:45:48.402118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nprint(history2.history.keys())\nacc_train = history2.history['acc']\nacc_val = history2.history['val_acc']\nepochs = range(len(acc_train))\n\nplt.plot(epochs, acc_train, 'g', label='Training Accuracy')\nplt.plot(epochs, acc_val, 'b', label='validation Accuracy')\nplt.title('Training Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.savefig('fig-Accuracy.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T23:45:52.169615Z","iopub.execute_input":"2024-05-07T23:45:52.170389Z","iopub.status.idle":"2024-05-07T23:45:52.574795Z","shell.execute_reply.started":"2024-05-07T23:45:52.170356Z","shell.execute_reply":"2024-05-07T23:45:52.573852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"intent = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/Intents-Dictionary.csv')\n\nintent.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T23:46:02.226755Z","iopub.execute_input":"2024-05-07T23:46:02.227132Z","iopub.status.idle":"2024-05-07T23:46:02.262431Z","shell.execute_reply.started":"2024-05-07T23:46:02.227101Z","shell.execute_reply":"2024-05-07T23:46:02.261410Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mp = {}\n\nfor i in range(intent.shape[0]):\n    mp[intent['Intent_en'][i]] = intent['Intent_ID'][i]","metadata":{"execution":{"iopub.status.busy":"2024-05-07T23:46:07.149630Z","iopub.execute_input":"2024-05-07T23:46:07.150780Z","iopub.status.idle":"2024-05-07T23:46:07.156848Z","shell.execute_reply.started":"2024-05-07T23:46:07.150738Z","shell.execute_reply":"2024-05-07T23:46:07.155909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = pd.read_csv('/kaggle/input/arabic-nlp/ArabicNLP/test/subtask1-test-set.csv')\n\nkf.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-07T23:46:08.779297Z","iopub.execute_input":"2024-05-07T23:46:08.779652Z","iopub.status.idle":"2024-05-07T23:46:08.844267Z","shell.execute_reply.started":"2024-05-07T23:46:08.779625Z","shell.execute_reply":"2024-05-07T23:46:08.843327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\n\nfor i in range(0, 3000):\n    example = kf['Query'][i]\n    ids = pre(example, return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)['input_ids']\n    pred = model.predict(ids)\n    index = tf.math.argmax(pred[0])\n    if(dialects[index] == 'MSA'):\n        pred = model1.predict(ids)\n        index = tf.math.argmax(pred[0])\n    else:\n        pred = model2.predict(ids)\n        index = tf.math.argmax(pred[0])\n#     print(classes[index] + \" with percentage: \" + str(pred[0][index] * 100) + \"\\n\")\n    preds.append(classes[index])\n    print(i)    ","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-05-08T00:06:00.342284Z","iopub.execute_input":"2024-05-08T00:06:00.343210Z","iopub.status.idle":"2024-05-08T00:06:07.183929Z","shell.execute_reply.started":"2024-05-08T00:06:00.343162Z","shell.execute_reply":"2024-05-08T00:06:07.182333Z"},"trusted":true},"execution_count":159,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 43ms/step\n1/1 [==============================] - 0s 40ms/step\n0\n1/1 [==============================] - 0s 49ms/step\n1/1 [==============================] - 0s 41ms/step\n1\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 40ms/step\n2\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 53ms/step\n3\n1/1 [==============================] - 0s 59ms/step\n1/1 [==============================] - 0s 38ms/step\n4\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 41ms/step\n5\n1/1 [==============================] - 0s 41ms/step\n1/1 [==============================] - 0s 55ms/step\n6\n1/1 [==============================] - 0s 43ms/step\n1/1 [==============================] - 0s 66ms/step\n7\n1/1 [==============================] - 0s 43ms/step\n1/1 [==============================] - 0s 42ms/step\n8\n1/1 [==============================] - 0s 46ms/step\n1/1 [==============================] - 0s 43ms/step\n9\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 45ms/step\n10\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 42ms/step\n11\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 45ms/step\n12\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 40ms/step\n13\n1/1 [==============================] - 0s 43ms/step\n1/1 [==============================] - 0s 75ms/step\n14\n1/1 [==============================] - 0s 45ms/step\n1/1 [==============================] - 0s 41ms/step\n15\n1/1 [==============================] - 0s 43ms/step\n1/1 [==============================] - 0s 40ms/step\n16\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 42ms/step\n17\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 39ms/step\n18\n1/1 [==============================] - 0s 44ms/step\n1/1 [==============================] - 0s 41ms/step\n19\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 41ms/step\n20\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 39ms/step\n21\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 38ms/step\n22\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 39ms/step\n23\n1/1 [==============================] - 0s 42ms/step\n1/1 [==============================] - 0s 39ms/step\n24\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 39ms/step\n25\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 39ms/step\n26\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 39ms/step\n27\n1/1 [==============================] - 0s 38ms/step\n1/1 [==============================] - 0s 38ms/step\n28\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 40ms/step\n29\n1/1 [==============================] - 0s 41ms/step\n1/1 [==============================] - 0s 39ms/step\n30\n1/1 [==============================] - 0s 40ms/step\n1/1 [==============================] - 0s 39ms/step\n31\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 39ms/step\n32\n1/1 [==============================] - 0s 39ms/step\n1/1 [==============================] - 0s 38ms/step\n33\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[159], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m example \u001b[38;5;241m=\u001b[39m kf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuery\u001b[39m\u001b[38;5;124m'\u001b[39m][i]\n\u001b[1;32m      5\u001b[0m ids \u001b[38;5;241m=\u001b[39m pre(example, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m'\u001b[39m, max_length\u001b[38;5;241m=\u001b[39mMAX_LENGHT, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 6\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m index \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39margmax(pred[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m(dialects[index] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMSA\u001b[39m\u001b[38;5;124m'\u001b[39m):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/training.py:2615\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2606\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2608\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing Model.predict with MultiWorkerMirroredStrategy \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2609\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor TPUStrategy and AutoShardPolicy.FILE might lead to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2612\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m   2613\u001b[0m         )\n\u001b[0;32m-> 2615\u001b[0m data_handler \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_data_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2616\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2617\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2618\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2619\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2620\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2621\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2622\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2623\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2624\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2625\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2626\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2628\u001b[0m \u001b[38;5;66;03m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(callbacks, callbacks_module\u001b[38;5;241m.\u001b[39mCallbackList):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/data_adapter.py:1682\u001b[0m, in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1680\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorExactEvalDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1682\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataHandler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/data_adapter.py:1287\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute, pss_evaluation_shards)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution \u001b[38;5;241m=\u001b[39m steps_per_execution\n\u001b[1;32m   1286\u001b[0m adapter_cls \u001b[38;5;241m=\u001b[39m select_data_adapter(x, y)\n\u001b[0;32m-> 1287\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapter \u001b[38;5;241m=\u001b[39m \u001b[43madapter_cls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minitial_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistribution_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_strategy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mget_strategy()\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/data_adapter.py:351\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m    349\u001b[0m indices_dataset \u001b[38;5;241m=\u001b[39m indices_dataset\u001b[38;5;241m.\u001b[39mflat_map(slice_batch_indices)\n\u001b[0;32m--> 351\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mslice_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindices_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshuffle_batch\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch):\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tf_keras/src/engine/data_adapter.py:392\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.slice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrab_batch\u001b[39m(i, data):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m d: tf\u001b[38;5;241m.\u001b[39mgather(d, i, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), data\n\u001b[1;32m    390\u001b[0m     )\n\u001b[0;32m--> 392\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrab_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUTOTUNE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# (unnecessary) input pipeline graph serialization and deserialization\u001b[39;00m\n\u001b[1;32m    396\u001b[0m options \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mOptions()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:2280\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m   2276\u001b[0m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001b[39;00m\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;66;03m# dataset_ops).\u001b[39;00m\n\u001b[1;32m   2278\u001b[0m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m   2279\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mops\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_op\n\u001b[0;32m-> 2280\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_op\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_v2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2281\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2282\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2284\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:40\u001b[0m, in \u001b[0;36m_map_v2\u001b[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _MapDataset(\n\u001b[1;32m     38\u001b[0m       input_dataset, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m      \u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/map_op.py:172\u001b[0m, in \u001b[0;36m_ParallelMapDataset.__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name \u001b[38;5;241m=\u001b[39m name\n\u001b[1;32m    163\u001b[0m variant_tensor \u001b[38;5;241m=\u001b[39m gen_dataset_ops\u001b[38;5;241m.\u001b[39mparallel_map_dataset_v2(\n\u001b[1;32m    164\u001b[0m     input_dataset\u001b[38;5;241m.\u001b[39m_variant_tensor,  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    170\u001b[0m     preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preserve_cardinality,\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_common_args)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariant_tensor\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:4468\u001b[0m, in \u001b[0;36mUnaryDataset.__init__\u001b[0;34m(self, input_dataset, variant_tensor)\u001b[0m\n\u001b[1;32m   4466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_dataset: DatasetV2, variant_tensor):\n\u001b[1;32m   4467\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m-> 4468\u001b[0m   \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mUnaryDataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvariant_tensor\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/dataset_ops.py:261\u001b[0m, in \u001b[0;36mDatasetV2.__init__\u001b[0;34m(self, variant_tensor)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEach input of dataset \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m should be a subclass of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.Dataset` but encountered \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(input_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    260\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m input_options \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options_attr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_attr\u001b[38;5;241m.\u001b[39m_set_mutable(\u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/options.py:705\u001b[0m, in \u001b[0;36mOptions.merge\u001b[0;34m(self, options)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\u001b[38;5;28mself\u001b[39m, options):\n\u001b[1;32m    692\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Merges itself with the given `tf.data.Options`.\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m  If this object and the `options` to merge set an option differently, a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;124;03m    the input `tf.data.Options`.\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 705\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptions_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_options\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/util/options.py:163\u001b[0m, in \u001b[0;36mmerge_options\u001b[0;34m(*options_list)\u001b[0m\n\u001b[1;32m    161\u001b[0m that \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(options, name)\n\u001b[1;32m    162\u001b[0m default \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(default_options, name)\n\u001b[0;32m--> 163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mthat\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m:\n\u001b[1;32m    164\u001b[0m   \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m this \u001b[38;5;241m==\u001b[39m default:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/util/options.py:41\u001b[0m, in \u001b[0;36mOptionsBase.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m):\n\u001b[1;32m     40\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_options\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mset\u001b[39m(other\u001b[38;5;241m.\u001b[39m_options):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m     42\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(other, name):\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"for i in range(3000, 6000):\n    example = kf['Query'][i]\n    ids = pre(example, return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)['input_ids']\n    pred = model.predict(ids)\n    index = tf.math.argmax(pred[0])\n    if(dialects[index] == 'MSA'):\n        pred = model1.predict(ids)\n        index = tf.math.argmax(pred[0])\n    else:\n        pred = model2.predict(ids)\n        index = tf.math.argmax(pred[0])\n#     print(classes[index] + \" with percentage: \" + str(pred[0][index] * 100) + \"\\n\")\n    preds.append(classes[index])\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2024-05-07T23:57:05.430240Z","iopub.execute_input":"2024-05-07T23:57:05.431017Z"},"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(6000, 9000):\n    example = kf['Query'][i]\n    ids = pre(example, return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)['input_ids']\n    pred = model.predict(ids)\n    index = tf.math.argmax(pred[0])\n    if(dialects[index] == 'MSA'):\n        pred = model1.predict(ids)\n        index = tf.math.argmax(pred[0])\n    else:\n        pred = model2.predict(ids)\n        index = tf.math.argmax(pred[0])\n#     print(classes[index] + \" with percentage: \" + str(pred[0][index] * 100) + \"\\n\")\n    preds.append(classes[index])\n    print(i)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(9000, 11721):\n    example = kf['Query'][i]\n    ids = pre(example, return_tensors=\"tf\", padding='max_length', max_length=MAX_LENGHT, truncation=True)['input_ids']\n    pred = model.predict(ids)\n    index = tf.math.argmax(pred[0])\n    if(dialects[index] == 'MSA'):\n        pred = model1.predict(ids)\n        index = tf.math.argmax(pred[0])\n    else:\n        pred = model2.predict(ids)\n        index = tf.math.argmax(pred[0])\n#     print(classes[index] + \" with percentage: \" + str(pred[0][index] * 100) + \"\\n\")\n    preds.append(classes[index])\n    print(i)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iids = []\nfor i in range(len(preds)):\n    iids.append(mp[preds[i]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = kf.drop(['Query'], axis = 1)\n\nkf['IntentID'] = iids\n\nkf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf.to_csv('/kaggle/working/Fired_from_NLP_subtask1_test_pred_3.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}